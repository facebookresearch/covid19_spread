% Created 2020-12-06 Sun 22:05
% Intended LaTeX compiler: pdflatex
\documentclass{article}
\usepackage[svgnames, table]{xcolor}
\usepackage{times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{icml2021}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{cleveref}
\usepackage{svg}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{grffile}
\usepackage{pgfplots}
\usepackage[caption=false]{subfig}
\usepackage{wrapfig}
\usepackage{microtype}
\usepackage{xspace}
\pgfplotsset{compat=newest}
\usepackage{tikz}
\usetikzlibrary{positioning,quotes}
\hypersetup{
colorlinks = true,
allcolors = {DarkBlue}
}
\captionsetup{labelfont=bf}
\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\AR}{\text{AR}}
\newcommand{\bAR}{\ensuremath{\beta}\text{-AR}\xspace}
\newcommand{\Set}[1]{\mathcal{#1}}
\newcommand{\risk}{\mathcal{R}}
\newcommand{\foi}{\lambda}
\newcommand{\E}{\mathbb{E}}
\newcommand{\todo}[1]{{\color{red} #1}}


\icmltitlerunning{Neural Relational Autoregression for High-Resolution COVID-19 Forecasting}

\begin{document}

\twocolumn[
\icmltitle{Neural Relational Autoregression \\ for High-Resolution COVID-19 Forecasting}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2021
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.

\begin{icmlauthorlist}
\icmlauthor{Matthew Le}{fair}
\icmlauthor{Mark Ibrahim}{fair}
\icmlauthor{Levent Sagun}{fair}
\icmlauthor{Timothee Lacroix}{fair}
\icmlauthor{Maximilian Nickel}{fair}
\end{icmlauthorlist}

\icmlaffiliation{fair}{Facebook AI Research}

\icmlcorrespondingauthor{Maximilian Nickel}{maxn@fb.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, COVID-19}

\vskip 0.3in
]

\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

% \maketitle

\begin{abstract}
Forecasting COVID-19 poses unique challenges due to the novelty of the disease,
its unknown characteristics, and substantial but varying interventions to reduce
its spread. To improve the quality and robustness of forecasts, we propose a new
method which aims to disentangle region-specific factors -- such as
demographics, enacted policies, and mobility -- from disease-inherent factors
that influence its spread. For this purpose, we combine recurrent neural
networks with a vector autoregressive model and train the joint model with a
specific regularization scheme that increases the coupling between regions. This
approach is akin to using Granger causality as a relational inductive bias and
allows us to train high-resolution models by borrowing statistical strength
across regions. In our experiments, we observe that our method achieves strong
performance in predicting the spread of COVID-19 when compared to
state-of-the-art forecasts.
\end{abstract}

\section{Introduction}
\label{sec:orgcdd5422}
Modeling the spread of COVID-19 at a high spatial and temporal resolution (i.e.,
confirmed cases at county or admin-3 level) has become an important task in the
public health response to the disease. For instance, accurate county-level
forecasts are not only central to monitor the state of the pandemic but are also
important to efficiently allocate scarce resources such as ventilators, personal
protective equipment, and ICU beds; and to make progress towards efficient early
detection systems.


\begin{figure}[t]
\includegraphics[width=.9\columnwidth]{img/nrar.png}
\caption{Ranking of county-level forecasts by average MAE over various forecast horizons. The proposed neural relational autoregressive model (\bAR) shows strong performance over all horizons when compared to state-of-the-art forecasts. Mean rank over all horizons in parentheses.}
\label{fig:ranking-covidhub-mae}
\end{figure}



\begin{figure}[t]
  \centering
\includegraphics[width=.8\columnwidth]{img/growth_example.png}
\caption{\label{fig:county-variability}Variability of growth in confirmed cases per region over time. Each line represents one county in the state. For \(y_t\) denoting the number of cases at time \(t\), growth rate is computed as \((y_{t+1} - y_t)/y_t\).}
\end{figure}

However, forecasting COVID-19 poses unique challenges -- in particular when
considering confirmed cases at high spatial resolution. Although there has been
considerable progress towards understanding the spread of the disease, there
still exists only limited data and knowledge about important factors that
influence its spread. This is only exacerbated by the naturally larger
noise-levels in county-level data as compared to more highly aggregated state-level
data. Due to the global nature of COVID-19, the available data is also
distributed among regions with very different properties, many of which may
affect its spread. This includes, for instance, demographics and population
densities, enacted policies, adherence to those policies, mobility patterns, and
geographic features such as temperature. In addition, testing and reporting can
vary considerably across regions and time. All these factors lead to
considerable variablity (see also \Cref{fig:county-variability}) and uncertainty in
the data and makes reliable forecasting at high spatial resolution difficult.

To alleviate these issues, we propose a new method for predicting the spread of
COVID-19 by combining recurrent neural networks with a vector autoregressive
model and a specific regularization relational scheme. Our approach is motivated
by two main aspects: First, we seek to develop an end-to-end differentiable
model, as this allows us to make efficient use of the limited available data
while also enabling us to estimate parameters of powerful models that can capture
the large variability of cases across locations and time. However, while such
flexible models are needed to account for possible influencing factors there
is little data to estimate them reliably and without overfitting. For this
reason, we seek, second, to disentangle region- and time-specific factors from
disease-inherent factors that influence its spread. This allows us to borrow
statistical strength between regions by coupling their predictions -- based on
the assumption that once a model has correctly accounted for region-specific
dynamics, information about the spread of the disease in region \(j\) can
also help to improve predictions for a related region \(i\). This
approach is akin to using \emph{Granger causality} as an inductive bias to improve
forecast quality and robustness.

Compared to existing state-of-the-art forecasting models, our method takes a
highly data-driven approach with fewer modeling assumptions as, for instance, in
very detailed compartmental models. As such, we see our approach as complementary
to existing models which provides strong forecasting performance at the cost of
reduced interpretability.



\begin{figure*}[t]\centering
\includegraphics[width=.25\textwidth]{img/logit_normal_0.png}\hspace{1em}
\includegraphics[width=.25\textwidth]{img/logit_normal_-1.png}\hspace{1em}
\includegraphics[width=.25\textwidth]{img/logit_normal_1.png}
\caption{The Logit-Normal distribution is a probability distribution of a random variable whose logit has a normal distribution, i.e., $\phi(\mathcal{N}(\mu, \sigma))$.}
\end{figure*}

\section{Neural Relational Autoregression}
\label{sec:org6298d16}
We consider the forecasting of \(m\) time series that are different realizations
of the same underlying disease process. Let \({\Set{Y} = \{(y_i^1, \ldots,
y_i^T)\}_{i=1}^m}\) denote the observed case counts where \(i\) indexes locations
and where \(T\) denotes the maximum observation time. Furthermore, let
\(\Set{Y}(\tau) = \{(y_i^t : t \leq \tau)\}_{i=1}^m\) denote the set of all
observed case counts up to time \(\tau \leq T\). We then model the case counts as
random variables
\begin{equation*}
    Y^{t+1}_i\ |\ \Set{Y}(t) \sim f(\foi_i^t)
\end{equation*}
where \(\foi_i^{t}\) denotes the \emph{force of infection}\footnote{Given \(y^t_i\) infected
individuals, the force of infection (or hazard) models the probability that a
susceptible individual at time \(t\) will become infected by time \(t+1\)} at time
\(t\) in location \(i\) and where \(f(x)\) denotes a probability distribution with
parameter \(x\) (e.g., a Poisson or Negative Binomial distribution).

Due to the different interventions during the course of the epidemic, we regard
\(\Set{Y}\) as a time-varying process that is influenced by external factors such
as policies, mobility, etc. For this reason, we decompose \(\foi_i^t\) into a
time-specific component \(\beta_i^t\) and a time-indepedent component
\(\foi_i\) such that
\begin{align*}
\foi_i^t = \beta_i^t \foi_i \quad\text{where}\quad \beta_i^t \in [0, 1],\, \foi_i > 0
\end{align*}

Hence, \(\beta_i^t\) can be understood as a dampening factor of the underlying
force of infection which models the effect of interventions and depends on time
and location. While some influencing factors for the evolution of \(\beta_i^t\)
might be known (e.g., mobility, population density, etc.), we assume that the
full set of influencing factors is unknown and will regard \(\beta_i^t\)
as a latent variable.

Using this decomposition, we then model the time-independent force of infection
as a autoregressive model of order \(p\),\footnote{AR models where \[Y_i^{t+1}\ |\
\Set{Y}(t) \sim \text{Poisson}(\foi_i^t)\] can be interpreted as approximations
of Reed-Frost chain binomial SIR models \citep{abbey1952reedfrost}. For a detailed
discussion see \citep{bauer2018stratified}.} i.e.,
\begin{align}
    \text{AR}(p): \foi_i = \sum_{\ell=0}^{p-1} w^\ell y_i^{t - \ell} \label{eq:foi-ar}
\end{align}
where \(\{w^\ell > 0\}_{l=0}^{p-1}\) are the parameters of the model which are
shared across locations \(i\). For the time-depdendent dampening \(\beta_i^t\) we
employ recurrent neural networks (RNNs;
\cite{elman1990finding,hochreiter1997long,cho2014properties}) such that
\begin{align}
    \text{RNN}: \beta_i^t = f_\theta(\{x_i^k\}_{k=0}^t) \label{eq:rnn}
\end{align}
where \(\theta\) are the parameters of the network which are again shared across
locations and where \(\{x_i^k\}_{k=0}^t\) denote observed input features to the
RNN (e.g., mobility in location \(i\) at time \(k\)). Although an RNN as in
\Cref{eq:rnn} has enough capacity to model the evolution of \(\beta_i^t\), the
limited data about the spread of COVID-19 makes it challenging to estimate its
parameters without overfitting. We seek therefore an inductive bias which allows
us to estimate \(\beta_i^t\) from few observations.


\subsection{Relational Inductive Bias}
\label{sec:orgac99b1b}

Since all regions are affected by the same underlying process, we assume that we
can borrow statistical strength between regions and use information about the
spread in region \(i\) to help predicting the spread in region \(j\) -- once we have
accounted for time- and location-dependent dynamics. A good model of \(\beta_i^t\)
should therefore help to improve the predictions of \(y_i^{t+1} / \beta_i^t\) from
cases in other regions \(y_j^t\). We interpret this as an inductive bias akin to
Granger causality \citep{granger1969investigating}\footnote{Granger causality is
defined as follows: Let \({X^t=\{X_t\}_{i=1}^t}\), \({Y^t=\{Y_t\}_{i=1}^t}\),
\({Z^t=\{Z_t\}_{i=1}^t}\) denote stochastic processes and let \(L\) denote a loss
function. Furthermore, let \[\risk(Y^{t+1} | Y^t, Z^t) = \E(L(Y_{t+1}, f(Y^t,
Z^t)))\] denote the expected loss (risk) of a predictor \(f\). We then say \(X\)
\emph{Granger-causes} \(Y\) if its inclusion in the predictor significantly improves
the forecast, i.e., if \[ \risk(Y^{t+1} | Y^t, X^t, Z^t) \ll \risk(Y^{t+1} |
Y^t, Z^t) \]} and extend \Cref{eq:foi-ar} to a \emph{vector autoregressive} model where
it is known that Granger causality is directly linked to its coefficients. In
particular, let
\begin{equation} \text{VAR}(p): \foi_i =
\sum_{\ell=0}^{p-1} \sum_{j=1}^m w_{ij}^\ell y_j^{t - \ell}
\end{equation}
be a vector autoregressive model of order \(p\). \emph{A time series \(y_j\) is then
Granger-causing \(y_i\) if and only if \(w_{ij} \neq 0\)} \citep{Seth2007granger}. For
causal discovery, coefficients \(w_{ij}\) are therefore often
\(\ell_1\)-regularized. Here, we take the opposite approach and seek solutions
in which many time-series can be considered Granger-causal
related. However, we do not force all time series to be related since this is
likely an unrealistic constraint. Instead, we assume \(\forall i \neq j : w_{ij}\)
are drawn from a logit-normal distribution \citep{atchison1980logistic}, what
allows us to specify a prior on the proportion of related and unrelated time
series.


In particular, let \(\phi(\cdot)\) denote the logistic function, let \({\forall i
\neq j : w_{ij} = \phi(\alpha_{ij})}\), and let \(\mathcal{N}(\mu, \sigma^2)\)
denote the Normal distribution with mean \(\mu\) and variance \(\sigma^2\). Putting
everything together, we then model the full \emph{time-varying} force of infection as
\begin{align}
\bAR(p): \quad \foi^{t+1}_i & =
\beta_i^t \sum_{\ell=0}^{p-1}\sum_{j=1}^m w_{ij}^\ell y_j^{t - \ell} \label{eq:beta-ar} \\
    \alpha_{ij} & \sim \mathcal{N}(\mu, \sigma^2) \quad \forall i \neq j \notag
\end{align}
Hence, the \(\bAR\) model consists of a standard \AR\xspace component (\(w_{ii} > 0\)) and
a relational component (\(w_{ij} \in [0, 1]\)) which aims to couple the different
regions. The number of non-zero entries in the ``adjacency matrix'' \(w_{ij}\) can
then be controlled through the logit-normal prior.


\subsection{Accounting for Overdispersion}
\label{sec:org2abffde}
Count data such as confirmed cases is naturally modeled using Poisson
distributions. However, COVID-19 case counts exhibit substantial overdispersion,
i.e., the variance of the observed counts can significantly exceed their mean
(e.g., see \cref{fig:dispersion}). For this
reason, we will model case counts with Negative Binomial distributions what
allows us to account for varying degrees of overdispersion \citep{lloyd_smith2007negativebinomial}. Specifically, we set
\begin{align*}
    y^{t+1}_{i} & \sim \text{NB}(\foi_i^{t}, \nu_i)
\end{align*}
where \(\foi^t_i\) and \(\nu_i\) are mean and dispersion parameter of the
distribution and \(\foi^t_i\) is modeled using the \bAR model of \cref{eq:beta-ar}. The
likelihood function in \cref{eq:objective} is then of the form
\begin{equation*}
p_\theta(y) = \frac{\Gamma(y + \nu)}{y!\Gamma(\nu)}\left(\frac{\mu}{\mu +\nu}\right)^{y}\left(1 + \frac{\mu}{\nu}\right)^{-\nu}
\quad \mu > 0, \nu > 0
\end{equation*}

\begin{figure}[t]
  \centering
\includegraphics[width=.8\columnwidth]{img/overdispersion_counties.png}
\caption{Overdispersion of daily case counts in US states and counties with most number of cases.}
\label{fig:dispersion}
\end{figure}



\subsection{Parameter Estimation and Implementation Details}
\label{sec:org751d6db}
To estimate the parameters of the model, we regularize the
model log-likelihood such that \(w_{ij}\) is drawn from a logit-normal
distribution with location \(\mu\) and scale \(\sigma\). Let \(\theta\) denote
the model parameters (i.e., \(\alpha_{ij}\) as well as parameters of the RNN).
and let \(p_\theta(y)\) denote the likelihood function of the \(\bAR\)
model. Furthermore, let \(q\) denote the prior normal
distribution for \(\alpha_{ij}\). We then maximize the regularized log-likelihood
\begin{equation}
\max_{\theta}\sum_y\log p_\theta(y) + \sum_{ij} \log q(\alpha_{ij}\,|\,\mu,\sigma). \label{eq:objective}
\end{equation}
We regard \(\mu, \sigma > 0\) as hyperparameters which allow us to control the
ratio of related and unrelated time series.

Since \Cref{eq:objective} is end-to-end differentiable we can jointly estimate the
parameters of the entire model using gradient-based optimization. We compute
gradients via automatic differentiation using the PyTorch framework
\citep{paszke2019pytorch}. To maximize \Cref{eq:objective} we then use the stochastic
optimization method AdamW \citep{loshchilov2018decoupled} where we decouple the
updates of the normally distributed parameters \(\alpha_{ij}\) from the adaptive
updates of the remaining parameters.

\input{results}

\section{Related Work}
\label{sec:org3676b8c}
We build on prior work that has proposed to use autoregressive models
for spatially and temporally aggregated disease surveillance data of endemic-epidemic
processes \citep{held2005statistical,meyer2014powerlaw,meyer2016socialcontact}.
Such autoregressive models are, for instance, used to monitor infectious
diseases by public health agencies like the Robert Koch Institute
\citep{salmon2016surveillance}.

Moreover, the negative binomial distribution has become a popular way to model
infectious diseases, largely to its ability to model count data with varying degrees
of overdispersion \citep{lloyd_smith2007negativebinomial}. Autoregressive models
in combination with negative binomial distributions have, for instance, been
used by \citet{bauer2018stratified,wakefield2019spatio,held2005statistical} to
model infectious disease count data.

\citet{valdes2005estimating} proposed a combination of VAR(1) models and \(\ell_1\)
regularization to for the discovery of Granger-causal relations to understand
brain connectivity. \citet{haufe2010sparse} proposed an improved estimator which
can be applied for VAR models of order \(p > 1\).

\section{Conclusion}
\label{sec:orgf720d80}
To improve the quality and robustness of forecasts, we propose a new method
which aims to disentangle region-specific factors -- such as demographics,
enacted policies, and mobility -- from disease-inherent factors that influence
its spread. For this purpose, we combine recurrent neural networks with a vector
autoregressive model and train the joint model with a specific regularization
scheme that increases the coupling between regions. In our experiments, we
observe that our method achieves strong performance in predicting the spread of
COVID-19 when compared to state-of-the-art forecasts. Through ablations of the
model, we show that the relational approach in general, the added logit-normal
regularization, and the negative binomial likelihood are all important factors
that contribute to the forecast quality. Compared to existing state-of-the-art
forecasting models, our method takes a highly data-driven approach with fewer
modeling assumptions as, for instance, in very detailed and mechanistic
compartmental models. As such, we see our approach as complementary to existing
models with focus on strong forecasting performance at the cost of reduced
interpretability.

\bibliographystyle{icml2021}
\bibliography{references}
\end{document}
