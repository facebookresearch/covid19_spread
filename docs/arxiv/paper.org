#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@
#+Title: Inducing Granger Causality {{{NEWLINE}}} for High-Resolution COVID-19 Forecasting
#+Author: Maximilian Nickel, Matt Le, Mark Ibrahim, Levent Sagun, Timothee Lacroix {{{NEWLINE}}} Facebook AI Research
#+Publisher: Facebook AI Research

#+OPTIONS: toc:nil date:nil

#+LATEX_CLASS: tufte
#+LATEX_CLASS_OPTIONS: [nobib]
#+LATEX_HEADER: \usepackage[svgnames]{xcolor}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{url}


#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \renewcommand{\maketitle}{%
#+LATEX_HEADER:   \newpage
#+LATEX_HEADER:   \global\@topnum\z@% prevent floats from being placed at the top of the page
#+LATEX_HEADER:   \begingroup
#+LATEX_HEADER:     \setlength{\parindent}{0pt}%
#+LATEX_HEADER:     \setlength{\parskip}{4pt}%
#+LATEX_HEADER:     {\Large\bf\@title}\par
#+LATEX_HEADER:     {\normalfont\normalsize\@author}\par
#+LATEX_HEADER:   \endgroup
#+LATEX_HEADER:   \thispagestyle{plain}% suppress the running head
#+LATEX_HEADER:   \tuftebreak% add some space before the text begins
#+LATEX_HEADER:   \@afterindentfalse\@afterheading% suppress indentation of the next paragraph
#+LATEX_HEADER: }

#+LATEX_HEADER: % Paragraph indentation and separation for normal text
#+LATEX_HEADER: \renewcommand{\@tufte@reset@par}{%
#+LATEX_HEADER:   \setlength{\RaggedRightParindent}{0pt}%
#+LATEX_HEADER:   \setlength{\JustifyingParindent}{0pt}%
#+LATEX_HEADER:   \setlength{\parindent}{0pt}%
#+LATEX_HEADER:   \setlength{\parskip}{0.5pc}%
#+LATEX_HEADER: }
#+LATEX_HEADER: \@tufte@reset@par
#+LATEX_HEADER: \makeatother
#+LATEX_HEADER: \fancyhead[RE,RO]{\newlinetospace{\color{gray}\plaintitle}\quad\thepage}

#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amssymb}
#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \usepackage{cleveref}
#+LATEX_HEADER: \usepackage{svg}
#+LATEX_HEADER: \usepackage{bm}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{multirow}
#+LATEX_HEADER: \usepackage{grffile}
#+LATEX_HEADER: \usepackage{pgfplots}
#+LATEX_HEADER: \usepackage[caption=false]{subfig}
#+LATEX_HEADER: \usepackage{wrapfig}
#+LATEX_HEADER: \usepackage{microtype}

#+LATEX_HEADER: \pgfplotsset{compat=newest}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{positioning,quotes}

#+LATEX_HEADER: \usepackage[style=authoryear,backend=bibtex,natbib,maxcitenames=2,doi=false]{biblatex}
#+LATEX_HEADER: \addbibresource{./references.bib}

#+LATEX_HEADER: \hypersetup{
#+LATEX_HEADER:     colorlinks = true,
#+LATEX_HEADER:     allcolors = {DarkBlue}
#+LATEX_HEADER: }

#+LATEX_HEADER: \renewcommand{\vec}[1]{\bm{#1}}
#+LATEX_HEADER: \newcommand{\AR}{\text{AR}}
#+LATEX_HEADER: \newcommand{\Set}[1]{\mathcal{#1}}
#+LATEX_HEADER: \newcommand{\risk}{\mathcal{R}}
#+LATEX_HEADER: \newcommand{\E}{\mathbb{E}}
#+LATEX_HEADER: \newcommand{\todo}[1]{{\color{red} #1}}

#+LATEX_HEADER: %\author{Maximilian Nickel\\Facebook AI Research\\New York, NY\\\texttt{maxn@fb.com}}

#+BEGIN_abstract
Forecasting COVID-19 poses unique challenges due to the novelty of the disease,
its unknown characteristics, and substantial but varying interventions to reduce
its spread. Here, we propose a new method to disentangle the properties of the
underlying contagion process from its concrete realizations across spatial
entities. Our aim is to separate region-specific aspects -- such as
demographics, enacted policies, and testing methods -- from disease-inherent
aspects that influence its spread. This allows us to train high-resolution
models which jointly model the spread and are able to borrow strength across
regions by increasing Granger Causality between different regions. In our
experiments, we demonstrate that our approach achieves strong performance in
predicting the spread of the COVID-19 and improves the robustness of forecasts.
#+END_abstract

* Introduction
Modeling the spread of COVID-19 at a high spatial and temporal resolution has
become a key task in the public health response to the disease. It is not only
important to understand the progress of the disease, but is also central to
efficiently allocate scarce resources such as ventilators, personal protective
equipment, and ICU beds -- and to issue early warnings about potential outbreaks.

#+ATTR_LATEX: :float margin :width \columnwidth
#+CAPTION: Variability of new cases per region and over time
[[file:img/cases_italy.png]]

However, forecasting COVID-19 poses unique challenges. Many characteristics that
influence its spread are still unknown what is only exacerbated by the little
data that exists about its spread -- especially during the beginning of the
pandemic. Even several months after the initial outbreak there exists
substantially less data than for other infectious diseases like influenza and
measles which have been monitored for decades. Due to its global nature,
COVID-19 occurs moreover in regions with very different properties that all may
affect its spread. This does not only include different demographics and
population densities, but also enacted policies, adherence to those policies,
mobility patterns, and geographic features such as temperature. In addition,
testing and reporting can vary considerably across regions what adds another
source of variability and uncertainty.All these factors make reliable forecasts
difficult, especially at high spatial resolution. While flexible, high-capacity
models are needed to account for region-specific aspects of the spread there is
very little data to estimate such models reliably and without overfitting.

To alleviate this issue, we propose a new method that employs /Granger
causality/ as an inductive bias to improve forecast quality. Although there
exists considerable variability across locations, the spread of the disease is
also governed by common, disease-inherent properties. Once we have correctly
accounted for region-specific dynamics, information about the spread of the
disease in region $j$ should therefore also help us to improve the predictions
for a related region $i$. Based on this assumption, our method then aims to
learn region-specific models that increase Granger causality between regions.
For this purpose, we use standard autoregressive models and a
specific-regularization scheme that increases the coupling between regions.
Notably, this approach optimizes the opposite objective as often used in causal
discovery where coupling between regions is penalized, e.g., via $\ell_1$
regularization.




* Method
We assume we have a set of time series which are different realizations of the
the same underlying contagion process. Let \(\Set{Y} = \{(y_i^1, \ldots,
y_i^T)\}_{i=1}^m\) denote the observed realizations where $i$ indexes locations and
where $T$ denotes the maximum observation time. Furthermore, let \(\lambda_i^t\)
denote the /force of infection/ at time \(t\) in location \(i\). We assume that
$\lambda_i^t$ can be decomposed into a time-dependent component $\beta_i^t$ and a
time-independent component $\lambda$ such that
\begin{equation*}
\lambda_i^t = \beta_i^t \lambda \quad\text{where}\quad \beta_i^t \in [0, 1],\, \lambda > 0
\end{equation*}

Hence, $\beta_i^t$ can be understood as a dampening factor of the underlying
force of infection that depends on time and location specific properties. While
some influencing factors for the evolution of $\beta_i^t$ are know (e.g.,
mobility, population density, etc.), the full dynamics are still unknown. We
will therefore regard $\beta_i^t$ as a latent variable which can depend on
observed variables $\vec{x}_i^t$. There exist many possible ways to model the
evolution of $\beta_i^t$ in this setting. In the following, we will use a classic /Elman RNN/
where
\begin{align}
    \beta_i^t & = \sigma(\vec{w}^\top \vec{z}_t)
    & \vec{z}_t & = \psi(W_z\vec{h}_t + \vec{b}_z) \label{eq:rnn} \\
    && \vec{h}_t & = \psi(W_h\vec{x} + U\vec{h}_{t-1} + \vec{b}_h)\notag
\end{align}

Although an RNN as in ref:eq:rnn will provide enough capacity to model the
evolution of $\beta_i^t$ there is not enough data to estimate its parameters
without serious overfitting. As an inductive bias, we seek therefore models of
$\beta_i^t$ that improve the predictability of $\lambda = \lambda_i^t /
\beta_i^t$ from information about the spread in other regions. We interpret this
inductive bias in terms of Granger causality, which is defined as follows: Let
$X^t=\{X_t\}_{i=1}^t$, $Y^t=\{Y_t\}_{i=1}^t$, $Z^t=\{Z_t\}_{i=1}^t$ denote
stochastic processes and let $L$ denote a loss function. Furthermore, let
$\risk(Y^{t+1} | Y^t, Z^t) = \E(L(Y_{t+1}, f(Y^t, Z^t)))$ denote the expected
loss (risk) of a predictor $f$. We then say $X$ Granger-causes $Y$ if
\begin{equation}
    \risk(Y^{t+1} | Y^t, X^t, Z^t) < \risk(Y^{t+1} | Y^t, Z^t)
\end{equation}

For a /multivariate autoregressive/ model, it is known that Granger causality is
directly linked to its coefficients. In particular, let
\begin{equation} \AR(p): \quad y_i^{t+1} =
\sum_{\ell=0}^{p-1} \sum_{j=1}^m \lambda_{ij}^\ell y_j^{t - \ell}
\end{equation}
be a multivariate autoregressive model of order $p$. /Time series $y_j$ is then
Granger causing $y_i$ if and only if $\lambda_{ij} \neq 0$/. For causal
discovery, coefficients $\lambda_{ij}$ are therefore often
\(\ell_1\)-regularized to encourage sparse solutions. Here, we take the opposite
approach and penalize solutions for which $\lambda_{ij} \approx 0$

In particular, let
\begin{align} \beta\AR(p): \quad y_i^{t+1} = & \beta_i^t
\sum_{\ell=0}^{p-1} \sum_{j=1}^m \lambda_{ij}^\ell y_j^{t - \ell} \\
& \text{s.t. } \lambda_{ij} > \gamma > 0 \notag
\end{align}
be denote our time-varying and location-dependent AR model and let $\theta$ denote
it's parameters (i.e., $\lambda_{ij}$ and well as the RNN). Furthermore, let
$p_\theta(Y)$ denote the likelihood of the $\beta\AR$ model. We then minimize
the regularized objective
\begin{equation}
\min_{\theta} -\log p_\theta(Y) + \eta \sum_{i \neq j} \max(0, \gamma - \lambda_{ij})
\end{equation}
where the $\eta, \gamma > 0$ are hyperparameters. The regularization term
${\max(0, \gamma - \lambda_{ij})}$ penalizes autoregression coefficient which are
smaller than $\gamma$ and therefore encourages models in which the different
time series are related in terms of Granger causality.

*** Overdispersion

#+ATTR_LATEX: :float margin :width .8\columnwidth
file:img/overdispersion_states.png

#+ATTR_LATEX: :float margin :width \columnwidth
file:img/overdispersion_counties.png

\begin{equation*}
\Pr(Y = y) = \frac{\Gamma(y + \nu)}{y!\Gamma(\nu)}\left(\frac{\mu}{\mu +\nu}\right)^{y}\left(1 + \frac{\mu}{\nu}\right)^{-\nu}
\quad \mu > 0, \nu > 0
\end{equation*}

\begin{equation*}
    y^{t+1}_{i} \sim \text{NB}(\eta_i^{t}, \nu_i)
\end{equation*}

\begin{equation*}
    \min_\theta -\sum_{y} \log \Pr_\theta(Y = y)
\end{equation*}


** Transfer Entropy and Granger Causality
Transfer entropy measures the directed, time-asymmetric transfer of information
between two random processes $Y_i$ and $Y_j$. Intuitively, it captures the amount of
uncertainty reduced in future values of $Y_i$ by knowing the past values of $Y_j$ given
past values of Y. Formally, \[ T_{j \to i} = p_\theta(y^{t+1}_i, \Set{Y}^t) \log
\frac{p_\theta(y^{t+1} | \Set{Y}^t)}{p_\theta(y^{t+1} | \Set{Y}^t \textbackslash
y^t_j)} \]

* Related Work
We build on prior work using autoregressive models designed for spatially and
temporally aggregated surveillance data of endemic-epidemic processes
cref:held2005statistical,meyer2014powerlaw,meyer2016socialcontact. Such
autoregressive models are, for instance, used to monitor infectious diseases
by public health agencies like the Robert Koch Institute cref:salmon2016surveillance

* Experiments

#+LATEX: \printbibliography
