region: nystate
population: &fpop data/population-data/US-states/new-york-population.csv
notebooks:
  backfill:
    - notebooks/NY.ipynb
    - "notebooks/Model Analysis.ipynb"
  cv:
    - "notebooks/Model Analysis.ipynb"
validation:
  days: 21
  output: validation.csv
forecast:
  output: forecast.csv
  days: &fdays 21
prediction_interval:
  output_mean: mean.csv
  output_std: std.csv
  intervals: [0.99, 0.95, 0.8]
  nsamples: 500
  batch_size: 10
backfill:
  # LANL
  #- 2020-04-05
  #- 2020-04-08
  #- 2020-04-12
  # - 2020-04-15
  - 2020-04-19
  # - 2020-04-22
  - 2020-04-26
  # - 2020-04-29
  - 2020-05-03
  # - 2020-05-06
  - 2020-05-10
  - 2020-05-17
  - 2020-05-24
  - 2020-05-31
  - 2020-06-07
  #- 2020-06-13
  #- 2020-06-21
  #- 2020-06-28
ar:
  data: data/nystate/data_cases.csv
  output: ar_model.bin
  preprocess: 
    smooth: [1, 3, 5]
  resources:
    gpus: 1
    cpus: 1
    memgb: 10
    timeout: 30
  train:
    fpop: *fpop
    activation: sigmoid
    no_cross_correlation: false
    decay: [latent2_1]
    window: [10, 15, 20, 25]
    lr: [0.001, 0.005]
    momentum: [0.9]
    weight_decay: [0.1, 0.2]
    niters: [20000]
    temp_smoothing: 0
    loss: nb
    t0: 10
    test_on: *fdays
sir:
  module: sir
  output: sir_model.npy
  data: data/nystate/data-new.csv
  train:
    fpop: *fpop
    window: 1
    recovery_days: 10
    distancing_reduction: 0.8
    days: *fdays
    # number of days to keep for forecast
    keep: *fdays
mhp:
  data: data/nystate/timeseries.h5
  output: mhp_model.bin
  resources:
    gpus: 1
  simulate:
    trials: 10
    max_events: 2000000
    days: *fdays
  train:
    dim: [10, 15, 20]
    base_intensity: [True, False]
    alpha_scale: [-10, -15]
    const_beta: [8, 10, 15]
    weight_decay: [0]
    max_events: [1000000]
    maxcor: [100]
    optim: lbfgs
    max_events: 500000
    epochs: 200
    sparse_grads: False
bar:
  output: bar_model.bin
  data: data/usa/data_cases_ny.csv
  resources:
    gpus: 1
    cpus: 1
    memgb: 15
    timeout: 3600
  #preprocess:
  #  smooth: 7
  train:
    fpop: *fpop
    # features: [[data/usa/county_features.pt]]
    time_features:
      -
        - data/usa/testing/total_features_county.pt
        - data/usa/fb/mobility_features_county_fb.pt
        - data/usa/fb/mobility_features_county_state_fb.pt
        - data/usa/google/mobility_features_county_google.pt
        - data/usa/google/mobility_features_county_state_google.pt
        - data/usa/google/weather_features_county.pt
        - data/usa/symptom-survey/fb-survey_smoothed_hh_cmnty_cli-county_state.pt
        - data/usa/symptom-survey/fb-survey_smoothed_wcli-county_state.pt
        - data/usa/symptom-survey/doctor-visits_smoothed_adj_cli-county.pt
    activation: sigmoid
    decay: [latent2_2]
    #window: [20, 25]
    window: [25]
    lr: [0.001]
    momentum: [0.99]
    weight_decay: [0.2, 0.3]
    niters: [5000]
    granger: [0.5]
    temporal: [2]
    eta: [0.5]
    loss: nb
    t0: 0
    n_models: 5
    test_on: *fdays
    n_models: 5
metasir:
  output: msir_model.bin
  data: data/usa/data_cases_ny.csv
  resources:
    gpus: 1
    cpus: 1
    memgb: 15
    timeout: 3600
  preprocess:
    smooth: 7
  train:
    fpop: data/usa/population.csv
    decay: [exp]
    adjoint: False
    method: euler
    niters: [4000]
    lr: [0.001]
    momentum: 0.9
    loss: normal
    t0: 50
    test_on: *fdays
